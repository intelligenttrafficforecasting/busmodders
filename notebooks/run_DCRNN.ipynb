{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../misc\")\n",
    "import pandas as pd\n",
    "from misc.MoviaBusDataset import MoviaBusDataset\n",
    "from misc.data_loader import load_network, adjacency_matrix\n",
    "import pickle\n",
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_hdf(\"../DCRNN/data/df_highway_2012_4mon_sample.h5\")\n",
    "base_dir = '../DCRNN/movia'\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "if not os.path.exists(os.path.join(base_dir,'out')):\n",
    "    os.makedirs(os.path.join(base_dir,'out'))\n",
    "if not os.path.exists(os.path.join(base_dir,'data')):\n",
    "    os.makedirs(os.path.join(base_dir,'data'))\n",
    "if not os.path.exists(os.path.join(base_dir,'model')):\n",
    "    os.makedirs(os.path.join(base_dir,'model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movia_train = MoviaBusDataset('../data/train/', interpolation=True, agg_time=10)\n",
    "movia_val =  MoviaBusDataset('../data/validation/', interpolation=True, agg_time=10)\n",
    "movia_test =  MoviaBusDataset('../data/test/', interpolation=True, agg_time=10)\n",
    "\n",
    "#movia_dataset.remove_trend()\n",
    "#data_file = os.path.join(base_dir,'movia.h5')\n",
    "#all_data.to_hdf(data_file,key='df',format='table')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#road_network = load_network()\n",
    "adj_mx = movia_train.adjacency_matrix\n",
    "adj_mx = adj_mx.astype('float32')\n",
    "with open(os.path.join(base_dir,'adj_mx.pkl'), 'wb') as f:\n",
    "    pickle.dump([-1, -1, adj_mx], f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train x:  (1429, 6, 192, 2) y: (1429, 6, 192, 2)\n",
      "val x:  (181, 6, 192, 2) y: (181, 6, 192, 2)\n",
      "test x:  (277, 6, 192, 2) y: (277, 6, 192, 2)\n"
     ]
    }
   ],
   "source": [
    "##TAKEN FROM generate_training_data.py\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def generate_graph_seq2seq_io_data(\n",
    "        df, x_offsets, y_offsets, add_time_in_day=True, add_day_in_week=False, scaler=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate samples from\n",
    "    :param df:\n",
    "    :param x_offsets:\n",
    "    :param y_offsets:\n",
    "    :param add_time_in_day:\n",
    "    :param add_day_in_week:\n",
    "    :param scaler:\n",
    "    :return:\n",
    "    # x: (epoch_size, input_length, num_nodes, input_dim)\n",
    "    # y: (epoch_size, output_length, num_nodes, output_dim)\n",
    "    \"\"\"\n",
    "\n",
    "    num_samples, num_nodes = df.shape\n",
    "    data = np.expand_dims(df.values, axis=-1)\n",
    "    data_list = [data]\n",
    "    if add_time_in_day:\n",
    "        time_ind = (df.index.values - df.index.values.astype(\"datetime64[D]\")) / np.timedelta64(1, \"D\")\n",
    "        time_in_day = np.tile(time_ind, [1, num_nodes, 1]).transpose((2, 1, 0))\n",
    "        data_list.append(time_in_day)\n",
    "    if add_day_in_week:\n",
    "        day_in_week = np.zeros(shape=(num_samples, num_nodes, 7))\n",
    "        day_in_week[np.arange(num_samples), :, df.index.dayofweek] = 1\n",
    "        data_list.append(day_in_week)\n",
    "\n",
    "    data = np.concatenate(data_list, axis=-1)\n",
    "    # epoch_len = num_samples + min(x_offsets) - max(y_offsets)\n",
    "    x, y = [], []\n",
    "    # t is the index of the last observation.\n",
    "    min_t = abs(min(x_offsets))\n",
    "    max_t = abs(num_samples - abs(max(y_offsets)))  # Exclusive\n",
    "    for t in range(min_t, max_t):\n",
    "        x_t = data[t + x_offsets, ...]\n",
    "        y_t = data[t + y_offsets, ...]\n",
    "        x.append(x_t)\n",
    "        y.append(y_t)\n",
    "    x = np.stack(x, axis=0)\n",
    "    y = np.stack(y, axis=0)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "#def generate_train_val_test(args):\n",
    "#df = pd.read_hdf(args.traffic_df_filename)\n",
    "# 0 is the latest observed sample.\n",
    "x_offsets = np.sort(\n",
    "    # np.concatenate(([-week_size + 1, -day_size + 1], np.arange(-11, 1, 1)))\n",
    "    #ADD +6 to go from 5*12 = 60mins of predtions to 10*6=60mins of predictions\n",
    "    np.concatenate((np.arange(-11+6, 1, 1),))\n",
    ")\n",
    "#ADD -6 to go from 5*12 = 60mins of predtions to 10*6=60mins of predictions\n",
    "y_offsets = np.sort(np.arange(1, 13-6, 1))\n",
    "# x: (num_samples, input_length, num_nodes, input_dim)\n",
    "# y: (num_samples, output_length, num_nodes, output_dim)\n",
    "movia_train_df = pd.concat(movia_train.dataframes)\n",
    "movia_train_df[movia_train_df.columns] = movia_train_df[movia_train_df.columns].astype('float32')\n",
    "\n",
    "x_train, y_train = generate_graph_seq2seq_io_data(\n",
    "    movia_train_df,\n",
    "    x_offsets=x_offsets,\n",
    "    y_offsets=y_offsets,\n",
    "    add_time_in_day=True,\n",
    "    add_day_in_week=False,\n",
    ")\n",
    "movia_val_df = pd.concat(movia_val.dataframes)\n",
    "movia_val_df[movia_val_df.columns] = movia_val_df[movia_val_df.columns].astype('float32')\n",
    "\n",
    "x_val, y_val = generate_graph_seq2seq_io_data(\n",
    "    movia_val_df,\n",
    "    x_offsets=x_offsets,\n",
    "    y_offsets=y_offsets,\n",
    "    add_time_in_day=True,\n",
    "    add_day_in_week=False,\n",
    ")\n",
    "\n",
    "movia_test_df = pd.concat(movia_test.dataframes)\n",
    "movia_test_df[movia_test_df.columns] = movia_test_df[movia_test_df.columns].astype('float32')\n",
    "\n",
    "x_test, y_test = generate_graph_seq2seq_io_data(\n",
    "    movia_test_df,\n",
    "    x_offsets=x_offsets,\n",
    "    y_offsets=y_offsets,\n",
    "    add_time_in_day=True,\n",
    "    add_day_in_week=False,\n",
    ")\n",
    "\n",
    "for cat in [\"train\", \"val\", \"test\"]:\n",
    "    _x, _y = locals()[\"x_\" + cat], locals()[\"y_\" + cat]\n",
    "    print(cat, \"x: \", _x.shape, \"y:\", _y.shape)\n",
    "    np.savez_compressed(\n",
    "        os.path.join(os.path.join(base_dir,'data'), \"%s.npz\" % cat),\n",
    "        x=_x,\n",
    "        y=_y,\n",
    "        x_offsets=x_offsets.reshape(list(x_offsets.shape) + [1]),\n",
    "        y_offsets=y_offsets.reshape(list(y_offsets.shape) + [1]),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'base_dir': 'data/model',\n",
    "    'log_level': 'INFO',\n",
    "    'data': {\n",
    "      'batch_size': 64,\n",
    "      'dataset_dir': 'movia/data',\n",
    "      'test_batch_size': 64,\n",
    "      'val_batch_size': 64,\n",
    "      'graph_pkl_filename': 'movia/adj_mx.pkl'\n",
    "    },\n",
    "    'model': {\n",
    "      'cl_decay_steps': 2000,\n",
    "      'filter_type': 'dual_random_walk',\n",
    "      'horizon': 6,\n",
    "      'input_dim': 2,\n",
    "      'l1_decay': 0,\n",
    "      'max_diffusion_step': 1,\n",
    "      'num_nodes': len(adj_mx),\n",
    "      'num_rnn_layers': 2,\n",
    "      'output_dim': 1,\n",
    "      'rnn_units': 64,\n",
    "      'seq_len': 6,\n",
    "      'use_curriculum_learning': True\n",
    "    },\n",
    "    'train': {\n",
    "      'base_lr': 0.01,\n",
    "      'dropout': 0,\n",
    "      'epoch': 0,\n",
    "      'epochs': 100,\n",
    "      'epsilon': 1.0e-3,\n",
    "      'global_step': 0,\n",
    "      'lr_decay_ratio': 0.1,\n",
    "      'max_grad_norm': 5,\n",
    "      'max_to_keep': 100,\n",
    "      'min_learning_rate': 2.0e-06,\n",
    "      'optimizer': 'adam',\n",
    "      'patience': 50,\n",
    "      'steps': [20, 30, 40, 50],\n",
    "      'test_every_n_epochs': 10\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(os.path.join(base_dir,'config.yml'), 'w') as outfile:\n",
    "    yaml.dump(config, outfile, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-14 14:12:22,350 - INFO - Log directory: data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/\n",
      "2018-12-14 14:12:22,353 - INFO - {'base_dir': 'data/model', 'log_level': 'INFO', 'data': {'batch_size': 64, 'dataset_dir': 'movia/data', 'test_batch_size': 64, 'val_batch_size': 64, 'graph_pkl_filename': 'movia/adj_mx.pkl'}, 'model': {'cl_decay_steps': 2000, 'filter_type': 'dual_random_walk', 'horizon': 6, 'input_dim': 2, 'l1_decay': 0, 'max_diffusion_step': 1, 'num_nodes': 192, 'num_rnn_layers': 2, 'output_dim': 1, 'rnn_units': 64, 'seq_len': 6, 'use_curriculum_learning': True}, 'train': {'base_lr': 0.01, 'dropout': 0, 'epoch': 0, 'epochs': 100, 'epsilon': 0.001, 'global_step': 0, 'lr_decay_ratio': 0.1, 'max_grad_norm': 5, 'max_to_keep': 100, 'min_learning_rate': 2e-06, 'optimizer': 'adam', 'patience': 50, 'steps': [20, 30, 40, 50], 'test_every_n_epochs': 10}}\n",
      "2018-12-14 14:12:22,581 - INFO - ('x_train', (1429, 6, 192, 2))\n",
      "2018-12-14 14:12:22,582 - INFO - ('y_train', (1429, 6, 192, 2))\n",
      "2018-12-14 14:12:22,582 - INFO - ('x_val', (181, 6, 192, 2))\n",
      "2018-12-14 14:12:22,583 - INFO - ('y_val', (181, 6, 192, 2))\n",
      "2018-12-14 14:12:22,583 - INFO - ('x_test', (277, 6, 192, 2))\n",
      "2018-12-14 14:12:22,584 - INFO - ('y_test', (277, 6, 192, 2))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/zhome/30/0/70339/devel/busmodders/DCRNN/lib/utils.py:104: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(d, -1).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-14 14:12:27,660 - INFO - Total number of trainable parameters: 223744\n",
      "2018-12-14 14:12:28,233 - INFO - Start training ...\n",
      "2018-12-14 14:12:35,609 - INFO - Epoch [0/100] (23) train_mae: 1.7616, val_mae: 1.6994 lr:0.010000 7.3s\n",
      "2018-12-14 14:12:35,734 - INFO - Val loss decrease from inf to 1.6994, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.6994-23\n",
      "2018-12-14 14:12:39,609 - INFO - Epoch [1/100] (46) train_mae: 1.5137, val_mae: 1.6173 lr:0.010000 3.9s\n",
      "2018-12-14 14:12:39,657 - INFO - Val loss decrease from 1.6994 to 1.6173, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.6173-46\n",
      "2018-12-14 14:12:43,916 - INFO - Epoch [2/100] (69) train_mae: 1.5000, val_mae: 1.6085 lr:0.010000 4.3s\n",
      "2018-12-14 14:12:43,962 - INFO - Val loss decrease from 1.6173 to 1.6085, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.6085-69\n",
      "2018-12-14 14:12:47,896 - INFO - Epoch [3/100] (92) train_mae: 1.4965, val_mae: 1.6064 lr:0.010000 3.9s\n",
      "2018-12-14 14:12:47,941 - INFO - Val loss decrease from 1.6085 to 1.6064, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.6064-92\n",
      "2018-12-14 14:12:50,875 - INFO - Epoch [4/100] (115) train_mae: 1.4945, val_mae: 1.6059 lr:0.010000 2.9s\n",
      "2018-12-14 14:12:50,923 - INFO - Val loss decrease from 1.6064 to 1.6059, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.6059-115\n",
      "2018-12-14 14:12:54,417 - INFO - Epoch [5/100] (138) train_mae: 1.4925, val_mae: 1.6065 lr:0.010000 3.5s\n",
      "2018-12-14 14:12:57,123 - INFO - Epoch [6/100] (161) train_mae: 1.4913, val_mae: 1.6090 lr:0.010000 2.7s\n",
      "2018-12-14 14:13:00,079 - INFO - Epoch [7/100] (184) train_mae: 1.4894, val_mae: 1.6052 lr:0.010000 3.0s\n",
      "2018-12-14 14:13:00,127 - INFO - Val loss decrease from 1.6059 to 1.6052, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.6052-184\n",
      "2018-12-14 14:13:02,973 - INFO - Epoch [8/100] (207) train_mae: 1.4878, val_mae: 1.6040 lr:0.010000 2.8s\n",
      "2018-12-14 14:13:03,020 - INFO - Val loss decrease from 1.6052 to 1.6040, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.6040-207\n",
      "2018-12-14 14:13:06,050 - INFO - Epoch [9/100] (230) train_mae: 1.4873, val_mae: 1.6033 lr:0.010000 3.0s\n",
      "2018-12-14 14:13:06,858 - INFO - Horizon 01, MAE: 1.52, MAPE: 0.4425, RMSE: 2.10\n",
      "2018-12-14 14:13:06,861 - INFO - Horizon 02, MAE: 1.57, MAPE: 0.4657, RMSE: 2.18\n",
      "2018-12-14 14:13:06,864 - INFO - Horizon 03, MAE: 1.61, MAPE: 0.4735, RMSE: 2.23\n",
      "2018-12-14 14:13:06,867 - INFO - Horizon 04, MAE: 1.64, MAPE: 0.4861, RMSE: 2.27\n",
      "2018-12-14 14:13:06,870 - INFO - Horizon 05, MAE: 1.66, MAPE: 0.4913, RMSE: 2.30\n",
      "2018-12-14 14:13:06,873 - INFO - Horizon 06, MAE: 1.67, MAPE: 0.4912, RMSE: 2.33\n",
      "2018-12-14 14:13:06,919 - INFO - Val loss decrease from 1.6040 to 1.6033, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.6033-230\n",
      "2018-12-14 14:13:10,427 - INFO - Epoch [10/100] (253) train_mae: 1.4868, val_mae: 1.6076 lr:0.010000 3.5s\n",
      "2018-12-14 14:13:13,202 - INFO - Epoch [11/100] (276) train_mae: 1.4857, val_mae: 1.6048 lr:0.010000 2.8s\n",
      "2018-12-14 14:13:16,238 - INFO - Epoch [12/100] (299) train_mae: 1.4851, val_mae: 1.6044 lr:0.010000 3.0s\n",
      "2018-12-14 14:13:19,544 - INFO - Epoch [13/100] (322) train_mae: 1.4845, val_mae: 1.6046 lr:0.010000 3.3s\n",
      "2018-12-14 14:13:23,033 - INFO - Epoch [14/100] (345) train_mae: 1.4836, val_mae: 1.6040 lr:0.010000 3.5s\n",
      "2018-12-14 14:13:26,339 - INFO - Epoch [15/100] (368) train_mae: 1.4827, val_mae: 1.6038 lr:0.010000 3.3s\n",
      "2018-12-14 14:13:29,563 - INFO - Epoch [16/100] (391) train_mae: 1.4820, val_mae: 1.6032 lr:0.010000 3.2s\n",
      "2018-12-14 14:13:29,613 - INFO - Val loss decrease from 1.6033 to 1.6032, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.6032-391\n",
      "2018-12-14 14:13:32,873 - INFO - Epoch [17/100] (414) train_mae: 1.4812, val_mae: 1.6018 lr:0.010000 3.3s\n",
      "2018-12-14 14:13:32,922 - INFO - Val loss decrease from 1.6032 to 1.6018, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.6018-414\n",
      "2018-12-14 14:13:36,196 - INFO - Epoch [18/100] (437) train_mae: 1.4812, val_mae: 1.6025 lr:0.010000 3.3s\n",
      "2018-12-14 14:13:39,497 - INFO - Epoch [19/100] (460) train_mae: 1.4805, val_mae: 1.6015 lr:0.010000 3.3s\n",
      "2018-12-14 14:13:40,166 - INFO - Horizon 01, MAE: 1.51, MAPE: 0.4374, RMSE: 2.09\n",
      "2018-12-14 14:13:40,170 - INFO - Horizon 02, MAE: 1.57, MAPE: 0.4632, RMSE: 2.18\n",
      "2018-12-14 14:13:40,173 - INFO - Horizon 03, MAE: 1.60, MAPE: 0.4733, RMSE: 2.23\n",
      "2018-12-14 14:13:40,176 - INFO - Horizon 04, MAE: 1.63, MAPE: 0.4876, RMSE: 2.27\n",
      "2018-12-14 14:13:40,179 - INFO - Horizon 05, MAE: 1.65, MAPE: 0.4925, RMSE: 2.30\n",
      "2018-12-14 14:13:40,182 - INFO - Horizon 06, MAE: 1.67, MAPE: 0.4922, RMSE: 2.33\n",
      "2018-12-14 14:13:40,231 - INFO - Val loss decrease from 1.6018 to 1.6015, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.6015-460\n",
      "2018-12-14 14:13:43,463 - INFO - Epoch [20/100] (483) train_mae: 1.4787, val_mae: 1.5970 lr:0.001000 3.2s\n",
      "2018-12-14 14:13:43,512 - INFO - Val loss decrease from 1.6015 to 1.5970, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5970-483\n",
      "2018-12-14 14:13:46,678 - INFO - Epoch [21/100] (506) train_mae: 1.4779, val_mae: 1.5967 lr:0.001000 3.2s\n",
      "2018-12-14 14:13:46,728 - INFO - Val loss decrease from 1.5970 to 1.5967, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5967-506\n",
      "2018-12-14 14:13:51,379 - INFO - Epoch [22/100] (529) train_mae: 1.4778, val_mae: 1.5965 lr:0.001000 4.6s\n",
      "2018-12-14 14:13:51,429 - INFO - Val loss decrease from 1.5967 to 1.5965, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5965-529\n",
      "2018-12-14 14:13:55,457 - INFO - Epoch [23/100] (552) train_mae: 1.4777, val_mae: 1.5966 lr:0.001000 4.0s\n",
      "2018-12-14 14:13:58,851 - INFO - Epoch [24/100] (575) train_mae: 1.4776, val_mae: 1.5968 lr:0.001000 3.4s\n",
      "2018-12-14 14:14:01,932 - INFO - Epoch [25/100] (598) train_mae: 1.4774, val_mae: 1.5969 lr:0.001000 3.1s\n",
      "2018-12-14 14:14:05,375 - INFO - Epoch [26/100] (621) train_mae: 1.4773, val_mae: 1.5970 lr:0.001000 3.4s\n",
      "2018-12-14 14:14:08,323 - INFO - Epoch [27/100] (644) train_mae: 1.4772, val_mae: 1.5970 lr:0.001000 2.9s\n",
      "2018-12-14 14:14:11,790 - INFO - Epoch [28/100] (667) train_mae: 1.4771, val_mae: 1.5970 lr:0.001000 3.5s\n",
      "2018-12-14 14:14:14,916 - INFO - Epoch [29/100] (690) train_mae: 1.4770, val_mae: 1.5968 lr:0.001000 3.1s\n",
      "2018-12-14 14:14:15,508 - INFO - Horizon 01, MAE: 1.50, MAPE: 0.4414, RMSE: 2.09\n",
      "2018-12-14 14:14:15,511 - INFO - Horizon 02, MAE: 1.57, MAPE: 0.4702, RMSE: 2.18\n",
      "2018-12-14 14:14:15,514 - INFO - Horizon 03, MAE: 1.60, MAPE: 0.4826, RMSE: 2.23\n",
      "2018-12-14 14:14:15,516 - INFO - Horizon 04, MAE: 1.63, MAPE: 0.4988, RMSE: 2.27\n",
      "2018-12-14 14:14:15,519 - INFO - Horizon 05, MAE: 1.65, MAPE: 0.5052, RMSE: 2.30\n",
      "2018-12-14 14:14:15,522 - INFO - Horizon 06, MAE: 1.66, MAPE: 0.5067, RMSE: 2.33\n",
      "2018-12-14 14:14:18,627 - INFO - Epoch [30/100] (713) train_mae: 1.4767, val_mae: 1.5957 lr:0.000100 3.1s\n",
      "2018-12-14 14:14:18,679 - INFO - Val loss decrease from 1.5965 to 1.5957, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5957-713\n",
      "2018-12-14 14:14:21,959 - INFO - Epoch [31/100] (736) train_mae: 1.4767, val_mae: 1.5958 lr:0.000100 3.3s\n",
      "2018-12-14 14:14:25,472 - INFO - Epoch [32/100] (759) train_mae: 1.4767, val_mae: 1.5958 lr:0.000100 3.5s\n",
      "2018-12-14 14:14:28,786 - INFO - Epoch [33/100] (782) train_mae: 1.4767, val_mae: 1.5958 lr:0.000100 3.3s\n",
      "2018-12-14 14:14:31,844 - INFO - Epoch [34/100] (805) train_mae: 1.4767, val_mae: 1.5958 lr:0.000100 3.1s\n",
      "2018-12-14 14:14:34,871 - INFO - Epoch [35/100] (828) train_mae: 1.4766, val_mae: 1.5958 lr:0.000100 3.0s\n",
      "2018-12-14 14:14:37,869 - INFO - Epoch [36/100] (851) train_mae: 1.4766, val_mae: 1.5958 lr:0.000100 3.0s\n",
      "2018-12-14 14:14:40,808 - INFO - Epoch [37/100] (874) train_mae: 1.4766, val_mae: 1.5958 lr:0.000100 2.9s\n",
      "2018-12-14 14:14:44,040 - INFO - Epoch [38/100] (897) train_mae: 1.4766, val_mae: 1.5958 lr:0.000100 3.2s\n",
      "2018-12-14 14:14:46,957 - INFO - Epoch [39/100] (920) train_mae: 1.4766, val_mae: 1.5958 lr:0.000100 2.9s\n",
      "2018-12-14 14:14:47,559 - INFO - Horizon 01, MAE: 1.50, MAPE: 0.4422, RMSE: 2.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-14 14:14:47,562 - INFO - Horizon 02, MAE: 1.57, MAPE: 0.4710, RMSE: 2.18\n",
      "2018-12-14 14:14:47,565 - INFO - Horizon 03, MAE: 1.60, MAPE: 0.4831, RMSE: 2.22\n",
      "2018-12-14 14:14:47,568 - INFO - Horizon 04, MAE: 1.63, MAPE: 0.4991, RMSE: 2.27\n",
      "2018-12-14 14:14:47,571 - INFO - Horizon 05, MAE: 1.65, MAPE: 0.5051, RMSE: 2.30\n",
      "2018-12-14 14:14:47,574 - INFO - Horizon 06, MAE: 1.66, MAPE: 0.5064, RMSE: 2.33\n",
      "2018-12-14 14:14:50,526 - INFO - Epoch [40/100] (943) train_mae: 1.4769, val_mae: 1.5957 lr:0.000010 3.0s\n",
      "2018-12-14 14:14:50,575 - INFO - Val loss decrease from 1.5957 to 1.5957, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5957-943\n",
      "2018-12-14 14:14:55,455 - INFO - Epoch [41/100] (966) train_mae: 1.4766, val_mae: 1.5956 lr:0.000010 4.9s\n",
      "2018-12-14 14:14:55,505 - INFO - Val loss decrease from 1.5957 to 1.5956, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5956-966\n",
      "2018-12-14 14:15:00,007 - INFO - Epoch [42/100] (989) train_mae: 1.4765, val_mae: 1.5956 lr:0.000010 4.5s\n",
      "2018-12-14 14:15:00,055 - INFO - Val loss decrease from 1.5956 to 1.5956, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5956-989\n",
      "2018-12-14 14:15:03,418 - INFO - Epoch [43/100] (1012) train_mae: 1.4765, val_mae: 1.5956 lr:0.000010 3.4s\n",
      "2018-12-14 14:15:03,465 - INFO - Val loss decrease from 1.5956 to 1.5956, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5956-1012\n",
      "2018-12-14 14:15:06,739 - INFO - Epoch [44/100] (1035) train_mae: 1.4765, val_mae: 1.5955 lr:0.000010 3.3s\n",
      "2018-12-14 14:15:06,785 - INFO - Val loss decrease from 1.5956 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1035\n",
      "2018-12-14 14:15:10,175 - INFO - Epoch [45/100] (1058) train_mae: 1.4765, val_mae: 1.5955 lr:0.000010 3.4s\n",
      "2018-12-14 14:15:10,222 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1058\n",
      "2018-12-14 14:15:13,818 - INFO - Epoch [46/100] (1081) train_mae: 1.4765, val_mae: 1.5955 lr:0.000010 3.6s\n",
      "2018-12-14 14:15:13,864 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1081\n",
      "2018-12-14 14:15:17,889 - INFO - Epoch [47/100] (1104) train_mae: 1.4765, val_mae: 1.5955 lr:0.000010 4.0s\n",
      "2018-12-14 14:15:17,937 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1104\n",
      "2018-12-14 14:15:21,582 - INFO - Epoch [48/100] (1127) train_mae: 1.4765, val_mae: 1.5955 lr:0.000010 3.6s\n",
      "2018-12-14 14:15:21,631 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1127\n",
      "2018-12-14 14:15:25,323 - INFO - Epoch [49/100] (1150) train_mae: 1.4765, val_mae: 1.5955 lr:0.000010 3.7s\n",
      "2018-12-14 14:15:26,064 - INFO - Horizon 01, MAE: 1.50, MAPE: 0.4423, RMSE: 2.09\n",
      "2018-12-14 14:15:26,067 - INFO - Horizon 02, MAE: 1.57, MAPE: 0.4711, RMSE: 2.18\n",
      "2018-12-14 14:15:26,070 - INFO - Horizon 03, MAE: 1.60, MAPE: 0.4833, RMSE: 2.22\n",
      "2018-12-14 14:15:26,073 - INFO - Horizon 04, MAE: 1.63, MAPE: 0.4992, RMSE: 2.26\n",
      "2018-12-14 14:15:26,075 - INFO - Horizon 05, MAE: 1.65, MAPE: 0.5052, RMSE: 2.30\n",
      "2018-12-14 14:15:26,078 - INFO - Horizon 06, MAE: 1.66, MAPE: 0.5064, RMSE: 2.33\n",
      "2018-12-14 14:15:26,126 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1150\n",
      "2018-12-14 14:15:29,698 - INFO - Epoch [50/100] (1173) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.6s\n",
      "2018-12-14 14:15:29,745 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1173\n",
      "2018-12-14 14:15:33,328 - INFO - Epoch [51/100] (1196) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.6s\n",
      "2018-12-14 14:15:33,376 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1196\n",
      "2018-12-14 14:15:36,970 - INFO - Epoch [52/100] (1219) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.6s\n",
      "2018-12-14 14:15:37,019 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1219\n",
      "2018-12-14 14:15:41,217 - INFO - Epoch [53/100] (1242) train_mae: 1.4770, val_mae: 1.5955 lr:0.000002 4.2s\n",
      "2018-12-14 14:15:41,264 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1242\n",
      "2018-12-14 14:15:45,259 - INFO - Epoch [54/100] (1265) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 4.0s\n",
      "2018-12-14 14:15:46,273 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1265\n",
      "2018-12-14 14:15:50,554 - INFO - Epoch [55/100] (1288) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 4.2s\n",
      "2018-12-14 14:15:50,604 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1288\n",
      "2018-12-14 14:15:54,101 - INFO - Epoch [56/100] (1311) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.5s\n",
      "2018-12-14 14:15:54,148 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1311\n",
      "2018-12-14 14:15:57,785 - INFO - Epoch [57/100] (1334) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.6s\n",
      "2018-12-14 14:15:57,835 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1334\n",
      "2018-12-14 14:16:01,651 - INFO - Epoch [58/100] (1357) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.8s\n",
      "2018-12-14 14:16:01,698 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1357\n",
      "2018-12-14 14:16:05,524 - INFO - Epoch [59/100] (1380) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.8s\n",
      "2018-12-14 14:16:06,177 - INFO - Horizon 01, MAE: 1.50, MAPE: 0.4423, RMSE: 2.09\n",
      "2018-12-14 14:16:06,180 - INFO - Horizon 02, MAE: 1.57, MAPE: 0.4711, RMSE: 2.18\n",
      "2018-12-14 14:16:06,183 - INFO - Horizon 03, MAE: 1.60, MAPE: 0.4833, RMSE: 2.22\n",
      "2018-12-14 14:16:06,185 - INFO - Horizon 04, MAE: 1.63, MAPE: 0.4992, RMSE: 2.26\n",
      "2018-12-14 14:16:06,188 - INFO - Horizon 05, MAE: 1.65, MAPE: 0.5052, RMSE: 2.30\n",
      "2018-12-14 14:16:06,190 - INFO - Horizon 06, MAE: 1.66, MAPE: 0.5064, RMSE: 2.33\n",
      "2018-12-14 14:16:06,237 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1380\n",
      "2018-12-14 14:16:09,706 - INFO - Epoch [60/100] (1403) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.5s\n",
      "2018-12-14 14:16:09,755 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1403\n",
      "2018-12-14 14:16:13,397 - INFO - Epoch [61/100] (1426) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.6s\n",
      "2018-12-14 14:16:13,446 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1426\n",
      "2018-12-14 14:16:16,937 - INFO - Epoch [62/100] (1449) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.5s\n",
      "2018-12-14 14:16:16,987 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1449\n",
      "2018-12-14 14:16:20,510 - INFO - Epoch [63/100] (1472) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.5s\n",
      "2018-12-14 14:16:20,559 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1472\n",
      "2018-12-14 14:16:24,095 - INFO - Epoch [64/100] (1495) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.5s\n",
      "2018-12-14 14:16:24,141 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1495\n",
      "2018-12-14 14:16:28,107 - INFO - Epoch [65/100] (1518) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 4.0s\n",
      "2018-12-14 14:16:28,156 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-14 14:16:32,227 - INFO - Epoch [66/100] (1541) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 4.1s\n",
      "2018-12-14 14:16:32,275 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1541\n",
      "2018-12-14 14:16:36,355 - INFO - Epoch [67/100] (1564) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 4.1s\n",
      "2018-12-14 14:16:36,404 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1564\n",
      "2018-12-14 14:16:40,724 - INFO - Epoch [68/100] (1587) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 4.3s\n",
      "2018-12-14 14:16:40,771 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1587\n",
      "2018-12-14 14:16:44,781 - INFO - Epoch [69/100] (1610) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 4.0s\n",
      "2018-12-14 14:16:45,559 - INFO - Horizon 01, MAE: 1.50, MAPE: 0.4423, RMSE: 2.09\n",
      "2018-12-14 14:16:45,563 - INFO - Horizon 02, MAE: 1.57, MAPE: 0.4711, RMSE: 2.18\n",
      "2018-12-14 14:16:45,565 - INFO - Horizon 03, MAE: 1.60, MAPE: 0.4833, RMSE: 2.22\n",
      "2018-12-14 14:16:45,568 - INFO - Horizon 04, MAE: 1.63, MAPE: 0.4992, RMSE: 2.26\n",
      "2018-12-14 14:16:45,570 - INFO - Horizon 05, MAE: 1.65, MAPE: 0.5052, RMSE: 2.30\n",
      "2018-12-14 14:16:45,573 - INFO - Horizon 06, MAE: 1.66, MAPE: 0.5064, RMSE: 2.33\n",
      "2018-12-14 14:16:45,620 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1610\n",
      "2018-12-14 14:16:49,392 - INFO - Epoch [70/100] (1633) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.8s\n",
      "2018-12-14 14:16:49,439 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1633\n",
      "2018-12-14 14:16:53,406 - INFO - Epoch [71/100] (1656) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 4.0s\n",
      "2018-12-14 14:16:53,457 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1656\n",
      "2018-12-14 14:16:57,031 - INFO - Epoch [72/100] (1679) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.6s\n",
      "2018-12-14 14:16:57,081 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1679\n",
      "2018-12-14 14:17:01,544 - INFO - Epoch [73/100] (1702) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 4.5s\n",
      "2018-12-14 14:17:01,593 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1702\n",
      "2018-12-14 14:17:05,570 - INFO - Epoch [74/100] (1725) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 4.0s\n",
      "2018-12-14 14:17:05,620 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1725\n",
      "2018-12-14 14:17:09,366 - INFO - Epoch [75/100] (1748) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.7s\n",
      "2018-12-14 14:17:09,415 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1748\n",
      "2018-12-14 14:17:13,316 - INFO - Epoch [76/100] (1771) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.9s\n",
      "2018-12-14 14:17:13,369 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1771\n",
      "2018-12-14 14:17:17,194 - INFO - Epoch [77/100] (1794) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.8s\n",
      "2018-12-14 14:17:17,244 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1794\n",
      "2018-12-14 14:17:20,956 - INFO - Epoch [78/100] (1817) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.7s\n",
      "2018-12-14 14:17:21,009 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1817\n",
      "2018-12-14 14:17:24,818 - INFO - Epoch [79/100] (1840) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.8s\n",
      "2018-12-14 14:17:25,646 - INFO - Horizon 01, MAE: 1.50, MAPE: 0.4423, RMSE: 2.09\n",
      "2018-12-14 14:17:25,649 - INFO - Horizon 02, MAE: 1.57, MAPE: 0.4711, RMSE: 2.18\n",
      "2018-12-14 14:17:25,652 - INFO - Horizon 03, MAE: 1.60, MAPE: 0.4833, RMSE: 2.22\n",
      "2018-12-14 14:17:25,655 - INFO - Horizon 04, MAE: 1.63, MAPE: 0.4992, RMSE: 2.26\n",
      "2018-12-14 14:17:25,657 - INFO - Horizon 05, MAE: 1.65, MAPE: 0.5052, RMSE: 2.30\n",
      "2018-12-14 14:17:25,660 - INFO - Horizon 06, MAE: 1.66, MAPE: 0.5064, RMSE: 2.33\n",
      "2018-12-14 14:17:25,710 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1840\n",
      "2018-12-14 14:17:29,247 - INFO - Epoch [80/100] (1863) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.5s\n",
      "2018-12-14 14:17:29,294 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1863\n",
      "2018-12-14 14:17:32,869 - INFO - Epoch [81/100] (1886) train_mae: 1.4770, val_mae: 1.5955 lr:0.000002 3.6s\n",
      "2018-12-14 14:17:32,919 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1886\n",
      "2018-12-14 14:17:36,869 - INFO - Epoch [82/100] (1909) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.9s\n",
      "2018-12-14 14:17:36,918 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1909\n",
      "2018-12-14 14:17:40,847 - INFO - Epoch [83/100] (1932) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.9s\n",
      "2018-12-14 14:17:45,002 - INFO - Epoch [84/100] (1955) train_mae: 1.4769, val_mae: 1.5955 lr:0.000002 4.1s\n",
      "2018-12-14 14:17:45,057 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1955\n",
      "2018-12-14 14:17:48,839 - INFO - Epoch [85/100] (1978) train_mae: 1.4769, val_mae: 1.5955 lr:0.000002 3.8s\n",
      "2018-12-14 14:17:48,889 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-1978\n",
      "2018-12-14 14:17:53,571 - INFO - Epoch [86/100] (2001) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 4.7s\n",
      "2018-12-14 14:17:53,620 - INFO - Val loss decrease from 1.5955 to 1.5955, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1214141222/models-1.5955-2001\n",
      "2018-12-14 14:17:57,248 - INFO - Epoch [87/100] (2024) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.6s\n",
      "2018-12-14 14:18:01,161 - INFO - Epoch [88/100] (2047) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.9s\n",
      "2018-12-14 14:18:04,252 - INFO - Epoch [89/100] (2070) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.1s\n",
      "2018-12-14 14:18:04,947 - INFO - Horizon 01, MAE: 1.50, MAPE: 0.4423, RMSE: 2.09\n",
      "2018-12-14 14:18:04,950 - INFO - Horizon 02, MAE: 1.57, MAPE: 0.4711, RMSE: 2.18\n",
      "2018-12-14 14:18:04,953 - INFO - Horizon 03, MAE: 1.60, MAPE: 0.4833, RMSE: 2.22\n",
      "2018-12-14 14:18:04,956 - INFO - Horizon 04, MAE: 1.63, MAPE: 0.4992, RMSE: 2.26\n",
      "2018-12-14 14:18:04,958 - INFO - Horizon 05, MAE: 1.65, MAPE: 0.5052, RMSE: 2.30\n",
      "2018-12-14 14:18:04,961 - INFO - Horizon 06, MAE: 1.66, MAPE: 0.5064, RMSE: 2.33\n",
      "2018-12-14 14:18:08,154 - INFO - Epoch [90/100] (2093) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.2s\n",
      "2018-12-14 14:18:11,282 - INFO - Epoch [91/100] (2116) train_mae: 1.4770, val_mae: 1.5955 lr:0.000002 3.1s\n",
      "2018-12-14 14:18:14,511 - INFO - Epoch [92/100] (2139) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.2s\n",
      "2018-12-14 14:18:17,743 - INFO - Epoch [93/100] (2162) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.2s\n",
      "2018-12-14 14:18:22,516 - INFO - Epoch [94/100] (2185) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 4.8s\n",
      "2018-12-14 14:18:26,642 - INFO - Epoch [95/100] (2208) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 4.1s\n",
      "2018-12-14 14:18:29,780 - INFO - Epoch [96/100] (2231) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.1s\n",
      "2018-12-14 14:18:33,287 - INFO - Epoch [97/100] (2254) train_mae: 1.4770, val_mae: 1.5955 lr:0.000002 3.5s\n",
      "2018-12-14 14:18:36,534 - INFO - Epoch [98/100] (2277) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.2s\n",
      "2018-12-14 14:18:40,198 - INFO - Epoch [99/100] (2300) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-14 14:18:40,899 - INFO - Horizon 01, MAE: 1.50, MAPE: 0.4423, RMSE: 2.09\n",
      "2018-12-14 14:18:40,902 - INFO - Horizon 02, MAE: 1.57, MAPE: 0.4711, RMSE: 2.18\n",
      "2018-12-14 14:18:40,904 - INFO - Horizon 03, MAE: 1.60, MAPE: 0.4833, RMSE: 2.22\n",
      "2018-12-14 14:18:40,907 - INFO - Horizon 04, MAE: 1.63, MAPE: 0.4992, RMSE: 2.26\n",
      "2018-12-14 14:18:40,910 - INFO - Horizon 05, MAE: 1.65, MAPE: 0.5052, RMSE: 2.30\n",
      "2018-12-14 14:18:40,912 - INFO - Horizon 06, MAE: 1.66, MAPE: 0.5064, RMSE: 2.33\n",
      "2018-12-14 14:18:44,304 - INFO - Epoch [100/100] (2323) train_mae: 1.4765, val_mae: 1.5955 lr:0.000002 3.4s\n",
      "2018-12-14 14:18:44,966 - INFO - Horizon 01, MAE: 1.50, MAPE: 0.4423, RMSE: 2.09\n",
      "2018-12-14 14:18:44,969 - INFO - Horizon 02, MAE: 1.57, MAPE: 0.4711, RMSE: 2.18\n",
      "2018-12-14 14:18:44,971 - INFO - Horizon 03, MAE: 1.60, MAPE: 0.4833, RMSE: 2.22\n",
      "2018-12-14 14:18:44,974 - INFO - Horizon 04, MAE: 1.63, MAPE: 0.4992, RMSE: 2.26\n",
      "2018-12-14 14:18:44,976 - INFO - Horizon 05, MAE: 1.65, MAPE: 0.5052, RMSE: 2.30\n",
      "2018-12-14 14:18:44,979 - INFO - Horizon 06, MAE: 1.66, MAPE: 0.5064, RMSE: 2.33\n",
      "Predictions saved as ../DCRNN/movia/out.npz.\n"
     ]
    }
   ],
   "source": [
    "#IF running into ValueError: Variable rnn/basic_rnn_cell/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at\n",
    "#Try restarting kernel\n",
    "os.chdir(os.path.join(base_dir,'..'))\n",
    "#%run run_demo.py --config_filename movia/config.yml --output_filename movia/out/out.npz\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from lib.utils import load_graph_data\n",
    "from model.dcrnn_supervisor import DCRNNSupervisor\n",
    "use_cpu_only = False\n",
    "graph_pkl_filename = 'movia/adj_mx.pkl'\n",
    "tf_config = tf.ConfigProto()\n",
    "\n",
    "if use_cpu_only:\n",
    "    tf_config = tf.ConfigProto(device_count={'GPU': 0})\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "_, _, adj_mx = load_graph_data(graph_pkl_filename)\n",
    "supervisor = None\n",
    "with tf.Session(config=tf_config) as sess:\n",
    "    supervisor = DCRNNSupervisor(adj_mx=adj_mx, **config)\n",
    "    supervisor.train(sess)\n",
    "    #supervisor.load(sess, config['train']['model_filename'])\n",
    "    outputs = supervisor.evaluate(sess)\n",
    "    np.savez_compressed(os.path.join(base_dir,'out.npz'), **outputs)\n",
    "    print('Predictions saved as {}.'.format(os.path.join(base_dir,'out.npz')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### diff 2 best\n",
    "### dropuout 0.2, 0.5, 0 ingen effekt\n",
    "###  1,3 layers no affect.\n",
    "### 128 notes no affect\n",
    "### laplace worse\n",
    "\n",
    "\n",
    "### diff 1\n",
    "```\n",
    "2018-12-10 19:18:20,415 - INFO - Horizon 01, MAE: 1.50, MAPE: 0.4415, RMSE: 2.08\n",
    "2018-12-10 19:18:20,418 - INFO - Horizon 02, MAE: 1.57, MAPE: 0.4702, RMSE: 2.17\n",
    "2018-12-10 19:18:20,421 - INFO - Horizon 03, MAE: 1.60, MAPE: 0.4847, RMSE: 2.22\n",
    "2018-12-10 19:18:20,423 - INFO - Horizon 04, MAE: 1.63, MAPE: 0.5004, RMSE: 2.26\n",
    "2018-12-10 19:18:20,426 - INFO - Horizon 05, MAE: 1.65, MAPE: 0.5073, RMSE: 2.30\n",
    "2018-12-10 19:18:20,429 - INFO - Horizon 06, MAE: 1.66, MAPE: 0.5103, RMSE: 2.32\n",
    "```\n",
    "\n",
    "### diff 2\n",
    "```\n",
    "2018-12-10 18:58:56,944 - WARNING - Early stopping at epoch: 80\n",
    "2018-12-10 18:58:58,147 - INFO - Horizon 01, MAE: 1.48, MAPE: 0.4400, RMSE: 2.07\n",
    "2018-12-10 18:58:58,150 - INFO - Horizon 02, MAE: 1.53, MAPE: 0.4668, RMSE: 2.14\n",
    "2018-12-10 18:58:58,154 - INFO - Horizon 03, MAE: 1.55, MAPE: 0.4792, RMSE: 2.18\n",
    "2018-12-10 18:58:58,157 - INFO - Horizon 04, MAE: 1.57, MAPE: 0.4917, RMSE: 2.21\n",
    "2018-12-10 18:58:58,160 - INFO - Horizon 05, MAE: 1.59, MAPE: 0.5029, RMSE: 2.24\n",
    "2018-12-10 18:58:58,163 - INFO - Horizon 06, MAE: 1.60, MAPE: 0.5120, RMSE: 2.27\n",
    "```\n",
    "\n",
    "### diff 2 - 3 layers\n",
    "```\n",
    "2018-12-10 20:41:26,454 - INFO - Horizon 01, MAE: 1.48, MAPE: 0.4389, RMSE: 2.07\n",
    "2018-12-10 20:41:26,457 - INFO - Horizon 02, MAE: 1.52, MAPE: 0.4667, RMSE: 2.13\n",
    "2018-12-10 20:41:26,460 - INFO - Horizon 03, MAE: 1.54, MAPE: 0.4764, RMSE: 2.17\n",
    "2018-12-10 20:41:26,462 - INFO - Horizon 04, MAE: 1.56, MAPE: 0.4856, RMSE: 2.21\n",
    "2018-12-10 20:41:26,465 - INFO - Horizon 05, MAE: 1.58, MAPE: 0.4960, RMSE: 2.23\n",
    "2018-12-10 20:41:26,467 - INFO - Horizon 06, MAE: 1.59, MAPE: 0.5079, RMSE: 2.26\n",
    "```\n",
    "\n",
    "### diff 1  layer -- no affect\n",
    "```\n",
    "2018-12-10 20:58:01,709 - INFO - Horizon 01, MAE: 1.49, MAPE: 0.4421, RMSE: 2.07\n",
    "2018-12-10 20:58:01,712 - INFO - Horizon 02, MAE: 1.54, MAPE: 0.4706, RMSE: 2.15\n",
    "2018-12-10 20:58:01,715 - INFO - Horizon 03, MAE: 1.56, MAPE: 0.4851, RMSE: 2.18\n",
    "2018-12-10 20:58:01,717 - INFO - Horizon 04, MAE: 1.58, MAPE: 0.5014, RMSE: 2.22\n",
    "2018-12-10 20:58:01,720 - INFO - Horizon 05, MAE: 1.60, MAPE: 0.5108, RMSE: 2.25\n",
    "2018-12-10 20:58:01,722 - INFO - Horizon 06, MAE: 1.61, MAPE: 0.5207, RMSE: 2.27\n",
    "```\n",
    "\n",
    "### diff 2 dropuout 0.2\n",
    "```\n",
    "2018-12-10 19:47:35,831 - INFO - Horizon 01, MAE: 1.48, MAPE: 0.4364, RMSE: 2.07\n",
    "2018-12-10 19:47:35,834 - INFO - Horizon 02, MAE: 1.53, MAPE: 0.4638, RMSE: 2.14\n",
    "2018-12-10 19:47:35,837 - INFO - Horizon 03, MAE: 1.54, MAPE: 0.4804, RMSE: 2.17\n",
    "2018-12-10 19:47:35,839 - INFO - Horizon 04, MAE: 1.56, MAPE: 0.4963, RMSE: 2.21\n",
    "2018-12-10 19:47:35,842 - INFO - Horizon 05, MAE: 1.58, MAPE: 0.5057, RMSE: 2.24\n",
    "2018-12-10 19:47:35,845 - INFO - Horizon 06, MAE: 1.59, MAPE: 0.5155, RMSE: 2.26\n",
    "```\n",
    "### diff 2 dropuout 0.5\n",
    "```\n",
    "2018-12-10 19:47:29,754 - INFO - Horizon 01, MAE: 1.48, MAPE: 0.4453, RMSE: 2.07\n",
    "2018-12-10 19:47:29,756 - INFO - Horizon 02, MAE: 1.53, MAPE: 0.4678, RMSE: 2.14\n",
    "2018-12-10 19:47:29,759 - INFO - Horizon 03, MAE: 1.55, MAPE: 0.4828, RMSE: 2.17\n",
    "2018-12-10 19:47:29,762 - INFO - Horizon 04, MAE: 1.57, MAPE: 0.4977, RMSE: 2.21\n",
    "2018-12-10 19:47:29,764 - INFO - Horizon 05, MAE: 1.58, MAPE: 0.5072, RMSE: 2.24\n",
    "2018-12-10 19:47:29,766 - INFO - Horizon 06, MAE: 1.60, MAPE: 0.5154, RMSE: 2.26\n",
    "```\n",
    "### diff 3\n",
    "```\n",
    "2018-12-10 19:01:31,102 - WARNING - Early stopping at epoch: 58\n",
    "2018-12-10 19:01:32,378 - INFO - Horizon 01, MAE: 1.59, MAPE: 0.5304, RMSE: 2.21\n",
    "2018-12-10 19:01:32,381 - INFO - Horizon 02, MAE: 1.60, MAPE: 0.5254, RMSE: 2.25\n",
    "2018-12-10 19:01:32,384 - INFO - Horizon 03, MAE: 1.61, MAPE: 0.5227, RMSE: 2.27\n",
    "2018-12-10 19:01:32,386 - INFO - Horizon 04, MAE: 1.62, MAPE: 0.5412, RMSE: 2.29\n",
    "2018-12-10 19:01:32,389 - INFO - Horizon 05, MAE: 1.63, MAPE: 0.5460, RMSE: 2.32\n",
    "2018-12-10 19:01:32,391 - INFO - Horizon 06, MAE: 1.63, MAPE: 0.5442, RMSE: 2.33\n",
    "```\n",
    "\n",
    "\n",
    "###  diff 2 128 notes\n",
    "```\n",
    "2018-12-10 21:18:15,171 - WARNING - Early stopping at epoch: 80\n",
    "2018-12-10 21:18:16,450 - INFO - Horizon 01, MAE: 1.48, MAPE: 0.4415, RMSE: 2.07\n",
    "2018-12-10 21:18:16,453 - INFO - Horizon 02, MAE: 1.53, MAPE: 0.4724, RMSE: 2.14\n",
    "2018-12-10 21:18:16,456 - INFO - Horizon 03, MAE: 1.55, MAPE: 0.4848, RMSE: 2.18\n",
    "2018-12-10 21:18:16,458 - INFO - Horizon 04, MAE: 1.56, MAPE: 0.4965, RMSE: 2.21\n",
    "2018-12-10 21:18:16,461 - INFO - Horizon 05, MAE: 1.58, MAPE: 0.5045, RMSE: 2.24\n",
    "2018-12-10 21:18:16,463 - INFO - Horizon 06, MAE: 1.59, MAPE: 0.5146, RMSE: 2.26\n",
    "```\n",
    "\n",
    "\n",
    "### diff2 laplacian \n",
    "```\n",
    "2018-12-10 21:34:08,644 - INFO - Horizon 01, MAE: 1.50, MAPE: 0.4444, RMSE: 2.09\n",
    "2018-12-10 21:34:08,647 - INFO - Horizon 02, MAE: 1.57, MAPE: 0.4723, RMSE: 2.18\n",
    "2018-12-10 21:34:08,650 - INFO - Horizon 03, MAE: 1.60, MAPE: 0.4856, RMSE: 2.22\n",
    "2018-12-10 21:34:08,652 - INFO - Horizon 04, MAE: 1.63, MAPE: 0.5040, RMSE: 2.26\n",
    "2018-12-10 21:34:08,654 - INFO - Horizon 05, MAE: 1.65, MAPE: 0.5113, RMSE: 2.30\n",
    "2018-12-10 21:34:08,657 - INFO - Horizon 06, MAE: 1.67, MAPE: 0.5134, RMSE: 2.33\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
