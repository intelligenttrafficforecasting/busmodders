{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../misc\")\n",
    "import pandas as pd\n",
    "from misc.MoviaBusDataset import MoviaBusDataset\n",
    "from misc.data_loader import load_network, adjacency_matrix\n",
    "import pickle\n",
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_hdf(\"../DCRNN/data/df_highway_2012_4mon_sample.h5\")\n",
    "base_dir = '../DCRNN/movia'\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "if not os.path.exists(os.path.join(base_dir,'out')):\n",
    "    os.makedirs(os.path.join(base_dir,'out'))\n",
    "if not os.path.exists(os.path.join(base_dir,'data')):\n",
    "    os.makedirs(os.path.join(base_dir,'data'))\n",
    "if not os.path.exists(os.path.join(base_dir,'model')):\n",
    "    os.makedirs(os.path.join(base_dir,'model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "movia_dataset =  MoviaBusDataset('../data/*/', interpolation=True,agg_time=10)\n",
    "#movia_dataset.remove_trend()\n",
    "all_data = pd.concat(movia_dataset.dataframes)\n",
    "#all_data = all_data.drop(['TimeOfDay'],axis=1)\n",
    "all_data[all_data.columns] = all_data[all_data.columns].astype('float32')\n",
    "data_file = os.path.join(base_dir,'movia.h5')\n",
    "all_data.to_hdf(data_file,key='df',format='table')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#road_network = load_network()\n",
    "adj_mx = movia_dataset.adjacency_matrix\n",
    "adj_mx = adj_mx.astype('float32')\n",
    "with open(os.path.join(base_dir,'adj_mx.pkl'), 'wb') as f:\n",
    "    pickle.dump([-1, -1, adj_mx], f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training data\n",
      "x shape:  (3829, 6, 192, 2) , y shape:  (3829, 6, 192, 2)\n",
      "train x:  (2680, 6, 192, 2) y: (2680, 6, 192, 2)\n",
      "val x:  (383, 6, 192, 2) y: (383, 6, 192, 2)\n",
      "test x:  (766, 6, 192, 2) y: (766, 6, 192, 2)\n"
     ]
    }
   ],
   "source": [
    "%run ../DCRNN/scripts/generate_training_data.py --output_dir ../DCRNN/movia/data --traffic_df_filename ../DCRNN/movia/movia.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'base_dir': 'data/model',\n",
    "    'log_level': 'INFO',\n",
    "    'data': {\n",
    "      'batch_size': 64,\n",
    "      'dataset_dir': 'movia/data',\n",
    "      'test_batch_size': 64,\n",
    "      'val_batch_size': 64,\n",
    "      'graph_pkl_filename': 'movia/adj_mx.pkl'\n",
    "    },\n",
    "    'model': {\n",
    "      'cl_decay_steps': 2000,\n",
    "      'filter_type': 'dual_random_walk',\n",
    "      'horizon': 6,\n",
    "      'input_dim': 2,\n",
    "      'l1_decay': 0,\n",
    "      'max_diffusion_step': 1,\n",
    "      'num_nodes': len(all_data.columns),\n",
    "      'num_rnn_layers': 2,\n",
    "      'output_dim': 1,\n",
    "      'rnn_units': 64,\n",
    "      'seq_len': 6,\n",
    "      'use_curriculum_learning': True\n",
    "    },\n",
    "    'train': {\n",
    "      'base_lr': 0.01,\n",
    "      'dropout': 0,\n",
    "      'epoch': 0,\n",
    "      'epochs': 100,\n",
    "      'epsilon': 1.0e-3,\n",
    "      'global_step': 0,\n",
    "      'lr_decay_ratio': 0.1,\n",
    "      'max_grad_norm': 5,\n",
    "      'max_to_keep': 100,\n",
    "      'min_learning_rate': 2.0e-06,\n",
    "      'optimizer': 'adam',\n",
    "      'patience': 50,\n",
    "      'steps': [20, 30, 40, 50],\n",
    "      'test_every_n_epochs': 10\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(os.path.join(base_dir,'config.yml'), 'w') as outfile:\n",
    "    yaml.dump(config, outfile, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-10 15:03:01,368 - INFO - Log directory: data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/\n",
      "2018-12-10 15:03:01,370 - INFO - {'base_dir': 'data/model', 'log_level': 'INFO', 'data': {'batch_size': 64, 'dataset_dir': 'movia/data', 'test_batch_size': 64, 'val_batch_size': 64, 'graph_pkl_filename': 'movia/adj_mx.pkl'}, 'model': {'cl_decay_steps': 2000, 'filter_type': 'dual_random_walk', 'horizon': 6, 'input_dim': 2, 'l1_decay': 0, 'max_diffusion_step': 1, 'num_nodes': 192, 'num_rnn_layers': 2, 'output_dim': 1, 'rnn_units': 64, 'seq_len': 6, 'use_curriculum_learning': True}, 'train': {'base_lr': 0.01, 'dropout': 0, 'epoch': 0, 'epochs': 100, 'epsilon': 0.001, 'global_step': 0, 'lr_decay_ratio': 0.1, 'max_grad_norm': 5, 'max_to_keep': 100, 'min_learning_rate': 2e-06, 'optimizer': 'adam', 'patience': 50, 'steps': [20, 30, 40, 50], 'test_every_n_epochs': 10}}\n",
      "2018-12-10 15:03:01,801 - INFO - ('x_train', (2680, 6, 192, 2))\n",
      "2018-12-10 15:03:01,802 - INFO - ('y_train', (2680, 6, 192, 2))\n",
      "2018-12-10 15:03:01,802 - INFO - ('x_val', (383, 6, 192, 2))\n",
      "2018-12-10 15:03:01,803 - INFO - ('y_val', (383, 6, 192, 2))\n",
      "2018-12-10 15:03:01,803 - INFO - ('x_test', (766, 6, 192, 2))\n",
      "2018-12-10 15:03:01,803 - INFO - ('y_test', (766, 6, 192, 2))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/zhome/30/0/70339/devel/busmodders/DCRNN/lib/utils.py:104: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(d, -1).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-10 15:03:06,424 - INFO - Total number of trainable parameters: 223744\n",
      "2018-12-10 15:03:06,896 - INFO - Start training ...\n",
      "2018-12-10 15:03:14,165 - INFO - Epoch [0/100] (42) train_mae: 1.6469, val_mae: 1.6318 lr:0.010000 7.2s\n",
      "2018-12-10 15:03:14,281 - INFO - Val loss decrease from inf to 1.6318, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.6318-42\n",
      "2018-12-10 15:03:18,304 - INFO - Epoch [1/100] (84) train_mae: 1.5075, val_mae: 1.6189 lr:0.010000 4.0s\n",
      "2018-12-10 15:03:18,353 - INFO - Val loss decrease from 1.6318 to 1.6189, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.6189-84\n",
      "2018-12-10 15:03:22,425 - INFO - Epoch [2/100] (126) train_mae: 1.5026, val_mae: 1.6158 lr:0.010000 4.1s\n",
      "2018-12-10 15:03:22,473 - INFO - Val loss decrease from 1.6189 to 1.6158, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.6158-126\n",
      "2018-12-10 15:03:26,506 - INFO - Epoch [3/100] (168) train_mae: 1.4991, val_mae: 1.6114 lr:0.010000 4.0s\n",
      "2018-12-10 15:03:26,555 - INFO - Val loss decrease from 1.6158 to 1.6114, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.6114-168\n",
      "2018-12-10 15:03:30,595 - INFO - Epoch [4/100] (210) train_mae: 1.4964, val_mae: 1.6104 lr:0.010000 4.0s\n",
      "2018-12-10 15:03:30,640 - INFO - Val loss decrease from 1.6114 to 1.6104, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.6104-210\n",
      "2018-12-10 15:03:34,665 - INFO - Epoch [5/100] (252) train_mae: 1.4947, val_mae: 1.6095 lr:0.010000 4.0s\n",
      "2018-12-10 15:03:34,711 - INFO - Val loss decrease from 1.6104 to 1.6095, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.6095-252\n",
      "2018-12-10 15:03:38,786 - INFO - Epoch [6/100] (294) train_mae: 1.4929, val_mae: 1.6092 lr:0.010000 4.1s\n",
      "2018-12-10 15:03:38,836 - INFO - Val loss decrease from 1.6095 to 1.6092, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.6092-294\n",
      "2018-12-10 15:03:42,988 - INFO - Epoch [7/100] (336) train_mae: 1.4919, val_mae: 1.6063 lr:0.010000 4.2s\n",
      "2018-12-10 15:03:43,040 - INFO - Val loss decrease from 1.6092 to 1.6063, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.6063-336\n",
      "2018-12-10 15:03:47,188 - INFO - Epoch [8/100] (378) train_mae: 1.4911, val_mae: 1.6033 lr:0.010000 4.1s\n",
      "2018-12-10 15:03:47,233 - INFO - Val loss decrease from 1.6063 to 1.6033, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.6033-378\n",
      "2018-12-10 15:03:51,304 - INFO - Epoch [9/100] (420) train_mae: 1.4903, val_mae: 1.6022 lr:0.010000 4.1s\n",
      "2018-12-10 15:03:52,046 - INFO - Horizon 01, MAE: 1.46, MAPE: 123437008773.3965, RMSE: 2.02\n",
      "2018-12-10 15:03:52,052 - INFO - Horizon 02, MAE: 1.49, MAPE: 130537731820.1233, RMSE: 2.06\n",
      "2018-12-10 15:03:52,058 - INFO - Horizon 03, MAE: 1.51, MAPE: 136575058262.6308, RMSE: 2.08\n",
      "2018-12-10 15:03:52,064 - INFO - Horizon 04, MAE: 1.52, MAPE: 131236891998.6572, RMSE: 2.10\n",
      "2018-12-10 15:03:52,069 - INFO - Horizon 05, MAE: 1.53, MAPE: 115728232109.7587, RMSE: 2.12\n",
      "2018-12-10 15:03:52,075 - INFO - Horizon 06, MAE: 1.55, MAPE: 112869728149.4716, RMSE: 2.14\n",
      "2018-12-10 15:03:52,124 - INFO - Val loss decrease from 1.6033 to 1.6022, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.6022-420\n",
      "2018-12-10 15:03:56,167 - INFO - Epoch [10/100] (462) train_mae: 1.4894, val_mae: 1.6008 lr:0.010000 4.0s\n",
      "2018-12-10 15:03:56,214 - INFO - Val loss decrease from 1.6022 to 1.6008, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.6008-462\n",
      "2018-12-10 15:04:00,335 - INFO - Epoch [11/100] (504) train_mae: 1.4884, val_mae: 1.5994 lr:0.010000 4.1s\n",
      "2018-12-10 15:04:00,384 - INFO - Val loss decrease from 1.6008 to 1.5994, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.5994-504\n",
      "2018-12-10 15:04:04,435 - INFO - Epoch [12/100] (546) train_mae: 1.4874, val_mae: 1.5981 lr:0.010000 4.0s\n",
      "2018-12-10 15:04:04,484 - INFO - Val loss decrease from 1.5994 to 1.5981, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.5981-546\n",
      "2018-12-10 15:04:08,506 - INFO - Epoch [13/100] (588) train_mae: 1.4862, val_mae: 1.5959 lr:0.010000 4.0s\n",
      "2018-12-10 15:04:08,552 - INFO - Val loss decrease from 1.5981 to 1.5959, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.5959-588\n",
      "2018-12-10 15:04:12,648 - INFO - Epoch [14/100] (630) train_mae: 1.4856, val_mae: 1.5921 lr:0.010000 4.1s\n",
      "2018-12-10 15:04:12,695 - INFO - Val loss decrease from 1.5959 to 1.5921, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.5921-630\n",
      "2018-12-10 15:04:16,729 - INFO - Epoch [15/100] (672) train_mae: 1.4830, val_mae: 1.5926 lr:0.010000 4.0s\n",
      "2018-12-10 15:04:20,757 - INFO - Epoch [16/100] (714) train_mae: 1.4810, val_mae: 1.5921 lr:0.010000 4.0s\n",
      "2018-12-10 15:04:24,847 - INFO - Epoch [17/100] (756) train_mae: 1.4790, val_mae: 1.5889 lr:0.010000 4.1s\n",
      "2018-12-10 15:04:24,896 - INFO - Val loss decrease from 1.5921 to 1.5889, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.5889-756\n",
      "2018-12-10 15:04:28,966 - INFO - Epoch [18/100] (798) train_mae: 1.4766, val_mae: 1.5842 lr:0.010000 4.1s\n",
      "2018-12-10 15:04:29,014 - INFO - Val loss decrease from 1.5889 to 1.5842, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.5842-798\n",
      "2018-12-10 15:04:33,198 - INFO - Epoch [19/100] (840) train_mae: 1.4737, val_mae: 1.5821 lr:0.010000 4.2s\n",
      "2018-12-10 15:04:33,960 - INFO - Horizon 01, MAE: 1.45, MAPE: 123662566688.2530, RMSE: 2.00\n",
      "2018-12-10 15:04:33,966 - INFO - Horizon 02, MAE: 1.48, MAPE: 130269128445.9581, RMSE: 2.04\n",
      "2018-12-10 15:04:33,971 - INFO - Horizon 03, MAE: 1.50, MAPE: 136001603090.6885, RMSE: 2.06\n",
      "2018-12-10 15:04:33,977 - INFO - Horizon 04, MAE: 1.51, MAPE: 132944236555.1140, RMSE: 2.08\n",
      "2018-12-10 15:04:33,983 - INFO - Horizon 05, MAE: 1.52, MAPE: 122178640915.1387, RMSE: 2.10\n",
      "2018-12-10 15:04:33,989 - INFO - Horizon 06, MAE: 1.53, MAPE: 117294988998.7157, RMSE: 2.12\n",
      "2018-12-10 15:04:34,035 - INFO - Val loss decrease from 1.5842 to 1.5821, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.5821-840\n",
      "2018-12-10 15:04:38,251 - INFO - Epoch [20/100] (882) train_mae: 1.4696, val_mae: 1.5701 lr:0.001000 4.2s\n",
      "2018-12-10 15:04:38,299 - INFO - Val loss decrease from 1.5821 to 1.5701, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.5701-882\n",
      "2018-12-10 15:04:42,475 - INFO - Epoch [21/100] (924) train_mae: 1.4676, val_mae: 1.5695 lr:0.001000 4.2s\n",
      "2018-12-10 15:04:42,525 - INFO - Val loss decrease from 1.5701 to 1.5695, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.5695-924\n",
      "2018-12-10 15:04:46,627 - INFO - Epoch [22/100] (966) train_mae: 1.4671, val_mae: 1.5689 lr:0.001000 4.1s\n",
      "2018-12-10 15:04:46,675 - INFO - Val loss decrease from 1.5695 to 1.5689, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.5689-966\n",
      "2018-12-10 15:04:50,718 - INFO - Epoch [23/100] (1008) train_mae: 1.4666, val_mae: 1.5681 lr:0.001000 4.0s\n",
      "2018-12-10 15:04:50,769 - INFO - Val loss decrease from 1.5689 to 1.5681, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.5681-1008\n",
      "2018-12-10 15:04:54,845 - INFO - Epoch [24/100] (1050) train_mae: 1.4661, val_mae: 1.5674 lr:0.001000 4.1s\n",
      "2018-12-10 15:04:54,893 - INFO - Val loss decrease from 1.5681 to 1.5674, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.5674-1050\n",
      "2018-12-10 15:04:58,988 - INFO - Epoch [25/100] (1092) train_mae: 1.4656, val_mae: 1.5667 lr:0.001000 4.1s\n",
      "2018-12-10 15:04:59,037 - INFO - Val loss decrease from 1.5674 to 1.5667, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.5667-1092\n",
      "2018-12-10 15:05:03,163 - INFO - Epoch [26/100] (1134) train_mae: 1.4651, val_mae: 1.5660 lr:0.001000 4.1s\n",
      "2018-12-10 15:05:03,211 - INFO - Val loss decrease from 1.5667 to 1.5660, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.5660-1134\n",
      "2018-12-10 15:05:07,315 - INFO - Epoch [27/100] (1176) train_mae: 1.4646, val_mae: 1.5653 lr:0.001000 4.1s\n",
      "2018-12-10 15:05:07,363 - INFO - Val loss decrease from 1.5660 to 1.5653, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.5653-1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-10 15:05:11,567 - INFO - Epoch [28/100] (1218) train_mae: 1.4640, val_mae: 1.5645 lr:0.001000 4.2s\n",
      "2018-12-10 15:05:11,617 - INFO - Val loss decrease from 1.5653 to 1.5645, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.5645-1218\n",
      "2018-12-10 15:05:15,705 - INFO - Epoch [29/100] (1260) train_mae: 1.4634, val_mae: 1.5637 lr:0.001000 4.1s\n",
      "2018-12-10 15:05:16,472 - INFO - Horizon 01, MAE: 1.43, MAPE: 120197155335.0545, RMSE: 2.01\n",
      "2018-12-10 15:05:16,478 - INFO - Horizon 02, MAE: 1.46, MAPE: 126242753572.9234, RMSE: 2.05\n",
      "2018-12-10 15:05:16,483 - INFO - Horizon 03, MAE: 1.47, MAPE: 130279842355.6361, RMSE: 2.07\n",
      "2018-12-10 15:05:16,489 - INFO - Horizon 04, MAE: 1.48, MAPE: 125048833440.5862, RMSE: 2.09\n",
      "2018-12-10 15:05:16,495 - INFO - Horizon 05, MAE: 1.50, MAPE: 114675323090.7209, RMSE: 2.11\n",
      "2018-12-10 15:05:16,501 - INFO - Horizon 06, MAE: 1.51, MAPE: 110600226393.9602, RMSE: 2.13\n",
      "2018-12-10 15:05:16,548 - INFO - Val loss decrease from 1.5645 to 1.5637, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.5637-1260\n",
      "2018-12-10 15:05:20,746 - INFO - Epoch [30/100] (1302) train_mae: 1.4629, val_mae: 1.5632 lr:0.000100 4.2s\n",
      "2018-12-10 15:05:20,794 - INFO - Val loss decrease from 1.5637 to 1.5632, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.5632-1302\n",
      "2018-12-10 15:05:24,930 - INFO - Epoch [31/100] (1344) train_mae: 1.4628, val_mae: 1.5631 lr:0.000100 4.1s\n",
      "2018-12-10 15:05:24,981 - INFO - Val loss decrease from 1.5632 to 1.5631, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.5631-1344\n",
      "2018-12-10 15:05:29,113 - INFO - Epoch [32/100] (1386) train_mae: 1.4627, val_mae: 1.5630 lr:0.000100 4.1s\n",
      "2018-12-10 15:05:29,161 - INFO - Val loss decrease from 1.5631 to 1.5630, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.5630-1386\n",
      "2018-12-10 15:05:33,296 - INFO - Epoch [33/100] (1428) train_mae: 1.4626, val_mae: 1.5629 lr:0.000100 4.1s\n",
      "2018-12-10 15:05:33,343 - INFO - Val loss decrease from 1.5630 to 1.5629, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.5629-1428\n",
      "2018-12-10 15:05:37,736 - INFO - Epoch [34/100] (1470) train_mae: 1.4626, val_mae: 1.5628 lr:0.000100 4.4s\n",
      "2018-12-10 15:05:37,826 - INFO - Val loss decrease from 1.5629 to 1.5628, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.5628-1470\n",
      "2018-12-10 15:05:42,153 - INFO - Epoch [35/100] (1512) train_mae: 1.4625, val_mae: 1.5627 lr:0.000100 4.3s\n",
      "2018-12-10 15:05:42,201 - INFO - Val loss decrease from 1.5628 to 1.5627, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.5627-1512\n",
      "2018-12-10 15:05:46,403 - INFO - Epoch [36/100] (1554) train_mae: 1.4625, val_mae: 1.5626 lr:0.000100 4.2s\n",
      "2018-12-10 15:05:46,518 - INFO - Val loss decrease from 1.5627 to 1.5626, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.5626-1554\n",
      "2018-12-10 15:05:50,809 - INFO - Epoch [37/100] (1596) train_mae: 1.4624, val_mae: 1.5625 lr:0.000100 4.3s\n",
      "2018-12-10 15:05:50,868 - INFO - Val loss decrease from 1.5626 to 1.5625, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.5625-1596\n",
      "2018-12-10 15:05:55,064 - INFO - Epoch [38/100] (1638) train_mae: 1.4623, val_mae: 1.5624 lr:0.000100 4.2s\n",
      "2018-12-10 15:05:55,114 - INFO - Val loss decrease from 1.5625 to 1.5624, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.5624-1638\n",
      "2018-12-10 15:05:59,215 - INFO - Epoch [39/100] (1680) train_mae: 1.4623, val_mae: 1.5623 lr:0.000100 4.1s\n",
      "2018-12-10 15:05:59,997 - INFO - Horizon 01, MAE: 1.43, MAPE: 120149590686.5597, RMSE: 2.01\n",
      "2018-12-10 15:06:00,003 - INFO - Horizon 02, MAE: 1.46, MAPE: 126192378120.1817, RMSE: 2.05\n",
      "2018-12-10 15:06:00,008 - INFO - Horizon 03, MAE: 1.47, MAPE: 130011841296.6560, RMSE: 2.07\n",
      "2018-12-10 15:06:00,014 - INFO - Horizon 04, MAE: 1.48, MAPE: 124606602672.6279, RMSE: 2.09\n",
      "2018-12-10 15:06:00,020 - INFO - Horizon 05, MAE: 1.49, MAPE: 114392643792.9382, RMSE: 2.11\n",
      "2018-12-10 15:06:00,026 - INFO - Horizon 06, MAE: 1.51, MAPE: 110268193754.0712, RMSE: 2.13\n",
      "2018-12-10 15:06:00,075 - INFO - Val loss decrease from 1.5624 to 1.5623, saving to data/model/dcrnn_DR_1_h_6_64-64_lr_0.01_bs_64_1210150301/models-1.5623-1680\n",
      "2018-12-10 15:06:04,215 - INFO - Epoch [40/100] (1722) train_mae: 1.4622, val_mae: 1.5626 lr:0.000010 4.1s\n",
      "2018-12-10 15:06:08,305 - INFO - Epoch [41/100] (1764) train_mae: 1.4622, val_mae: 1.5627 lr:0.000010 4.1s\n",
      "2018-12-10 15:06:12,619 - INFO - Epoch [42/100] (1806) train_mae: 1.4622, val_mae: 1.5627 lr:0.000010 4.3s\n",
      "2018-12-10 15:06:16,770 - INFO - Epoch [43/100] (1848) train_mae: 1.4622, val_mae: 1.5627 lr:0.000010 4.1s\n",
      "2018-12-10 15:06:20,914 - INFO - Epoch [44/100] (1890) train_mae: 1.4622, val_mae: 1.5627 lr:0.000010 4.1s\n",
      "2018-12-10 15:06:25,240 - INFO - Epoch [45/100] (1932) train_mae: 1.4621, val_mae: 1.5627 lr:0.000010 4.3s\n",
      "2018-12-10 15:06:29,492 - INFO - Epoch [46/100] (1974) train_mae: 1.4621, val_mae: 1.5627 lr:0.000010 4.2s\n",
      "2018-12-10 15:06:33,743 - INFO - Epoch [47/100] (2016) train_mae: 1.4621, val_mae: 1.5626 lr:0.000010 4.2s\n",
      "2018-12-10 15:06:37,984 - INFO - Epoch [48/100] (2058) train_mae: 1.4621, val_mae: 1.5626 lr:0.000010 4.2s\n",
      "2018-12-10 15:06:42,230 - INFO - Epoch [49/100] (2100) train_mae: 1.4621, val_mae: 1.5626 lr:0.000010 4.2s\n",
      "2018-12-10 15:06:43,035 - INFO - Horizon 01, MAE: 1.43, MAPE: 119932724362.5066, RMSE: 2.01\n",
      "2018-12-10 15:06:43,041 - INFO - Horizon 02, MAE: 1.46, MAPE: 125922581066.7984, RMSE: 2.05\n",
      "2018-12-10 15:06:43,047 - INFO - Horizon 03, MAE: 1.47, MAPE: 129682550103.5059, RMSE: 2.07\n",
      "2018-12-10 15:06:43,053 - INFO - Horizon 04, MAE: 1.48, MAPE: 124164740594.5760, RMSE: 2.09\n",
      "2018-12-10 15:06:43,059 - INFO - Horizon 05, MAE: 1.49, MAPE: 113879237620.8078, RMSE: 2.11\n",
      "2018-12-10 15:06:43,065 - INFO - Horizon 06, MAE: 1.51, MAPE: 109752228654.9573, RMSE: 2.13\n",
      "2018-12-10 15:06:47,359 - INFO - Epoch [50/100] (2142) train_mae: 1.4621, val_mae: 1.5626 lr:0.000002 4.3s\n",
      "2018-12-10 15:06:51,646 - INFO - Epoch [51/100] (2184) train_mae: 1.4621, val_mae: 1.5626 lr:0.000002 4.3s\n",
      "2018-12-10 15:06:55,830 - INFO - Epoch [52/100] (2226) train_mae: 1.4621, val_mae: 1.5626 lr:0.000002 4.2s\n",
      "2018-12-10 15:07:00,098 - INFO - Epoch [53/100] (2268) train_mae: 1.4624, val_mae: 1.5626 lr:0.000002 4.3s\n",
      "2018-12-10 15:07:04,343 - INFO - Epoch [54/100] (2310) train_mae: 1.4621, val_mae: 1.5626 lr:0.000002 4.2s\n",
      "2018-12-10 15:07:08,724 - INFO - Epoch [55/100] (2352) train_mae: 1.4621, val_mae: 1.5626 lr:0.000002 4.4s\n",
      "2018-12-10 15:07:13,024 - INFO - Epoch [56/100] (2394) train_mae: 1.4621, val_mae: 1.5626 lr:0.000002 4.3s\n",
      "2018-12-10 15:07:17,305 - INFO - Epoch [57/100] (2436) train_mae: 1.4621, val_mae: 1.5626 lr:0.000002 4.3s\n",
      "2018-12-10 15:07:21,644 - INFO - Epoch [58/100] (2478) train_mae: 1.4621, val_mae: 1.5626 lr:0.000002 4.3s\n",
      "2018-12-10 15:07:25,927 - INFO - Epoch [59/100] (2520) train_mae: 1.4624, val_mae: 1.5626 lr:0.000002 4.3s\n",
      "2018-12-10 15:07:26,744 - INFO - Horizon 01, MAE: 1.43, MAPE: 119926803421.6119, RMSE: 2.01\n",
      "2018-12-10 15:07:26,750 - INFO - Horizon 02, MAE: 1.46, MAPE: 125915857038.9760, RMSE: 2.05\n",
      "2018-12-10 15:07:26,756 - INFO - Horizon 03, MAE: 1.47, MAPE: 129674519234.2283, RMSE: 2.07\n",
      "2018-12-10 15:07:26,762 - INFO - Horizon 04, MAE: 1.48, MAPE: 124154599796.9154, RMSE: 2.09\n",
      "2018-12-10 15:07:26,768 - INFO - Horizon 05, MAE: 1.49, MAPE: 113872020789.6434, RMSE: 2.11\n",
      "2018-12-10 15:07:26,773 - INFO - Horizon 06, MAE: 1.51, MAPE: 109749304688.4612, RMSE: 2.13\n",
      "2018-12-10 15:07:30,988 - INFO - Epoch [60/100] (2562) train_mae: 1.4621, val_mae: 1.5626 lr:0.000002 4.2s\n",
      "2018-12-10 15:07:35,214 - INFO - Epoch [61/100] (2604) train_mae: 1.4623, val_mae: 1.5626 lr:0.000002 4.2s\n",
      "2018-12-10 15:07:39,564 - INFO - Epoch [62/100] (2646) train_mae: 1.4621, val_mae: 1.5626 lr:0.000002 4.3s\n",
      "2018-12-10 15:07:43,814 - INFO - Epoch [63/100] (2688) train_mae: 1.4621, val_mae: 1.5626 lr:0.000002 4.2s\n",
      "2018-12-10 15:07:48,078 - INFO - Epoch [64/100] (2730) train_mae: 1.4623, val_mae: 1.5626 lr:0.000002 4.3s\n",
      "2018-12-10 15:07:52,324 - INFO - Epoch [65/100] (2772) train_mae: 1.4621, val_mae: 1.5626 lr:0.000002 4.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-10 15:07:56,633 - INFO - Epoch [66/100] (2814) train_mae: 1.4624, val_mae: 1.5626 lr:0.000002 4.3s\n",
      "2018-12-10 15:08:00,891 - INFO - Epoch [67/100] (2856) train_mae: 1.4622, val_mae: 1.5626 lr:0.000002 4.3s\n",
      "2018-12-10 15:08:05,203 - INFO - Epoch [68/100] (2898) train_mae: 1.4621, val_mae: 1.5626 lr:0.000002 4.3s\n",
      "2018-12-10 15:08:09,569 - INFO - Epoch [69/100] (2940) train_mae: 1.4621, val_mae: 1.5626 lr:0.000002 4.4s\n",
      "2018-12-10 15:08:10,404 - INFO - Horizon 01, MAE: 1.43, MAPE: 119924930768.9122, RMSE: 2.01\n",
      "2018-12-10 15:08:10,410 - INFO - Horizon 02, MAE: 1.46, MAPE: 125912772455.0943, RMSE: 2.05\n",
      "2018-12-10 15:08:10,416 - INFO - Horizon 03, MAE: 1.47, MAPE: 129668634797.2848, RMSE: 2.07\n",
      "2018-12-10 15:08:10,422 - INFO - Horizon 04, MAE: 1.48, MAPE: 124146441163.8083, RMSE: 2.09\n",
      "2018-12-10 15:08:10,428 - INFO - Horizon 05, MAE: 1.49, MAPE: 113867742526.5555, RMSE: 2.11\n",
      "2018-12-10 15:08:10,434 - INFO - Horizon 06, MAE: 1.51, MAPE: 109748377488.0991, RMSE: 2.13\n",
      "2018-12-10 15:08:14,715 - INFO - Epoch [70/100] (2982) train_mae: 1.4623, val_mae: 1.5626 lr:0.000002 4.3s\n",
      "2018-12-10 15:08:19,007 - INFO - Epoch [71/100] (3024) train_mae: 1.4626, val_mae: 1.5626 lr:0.000002 4.3s\n",
      "2018-12-10 15:08:23,359 - INFO - Epoch [72/100] (3066) train_mae: 1.4623, val_mae: 1.5626 lr:0.000002 4.3s\n",
      "2018-12-10 15:08:27,669 - INFO - Epoch [73/100] (3108) train_mae: 1.4621, val_mae: 1.5626 lr:0.000002 4.3s\n",
      "2018-12-10 15:08:31,880 - INFO - Epoch [74/100] (3150) train_mae: 1.4623, val_mae: 1.5626 lr:0.000002 4.2s\n",
      "2018-12-10 15:08:36,067 - INFO - Epoch [75/100] (3192) train_mae: 1.4621, val_mae: 1.5626 lr:0.000002 4.2s\n",
      "2018-12-10 15:08:40,404 - INFO - Epoch [76/100] (3234) train_mae: 1.4623, val_mae: 1.5626 lr:0.000002 4.3s\n",
      "2018-12-10 15:08:44,588 - INFO - Epoch [77/100] (3276) train_mae: 1.4621, val_mae: 1.5626 lr:0.000002 4.2s\n",
      "2018-12-10 15:08:48,860 - INFO - Epoch [78/100] (3318) train_mae: 1.4621, val_mae: 1.5626 lr:0.000002 4.3s\n",
      "2018-12-10 15:08:53,209 - INFO - Epoch [79/100] (3360) train_mae: 1.4622, val_mae: 1.5626 lr:0.000002 4.3s\n",
      "2018-12-10 15:08:54,091 - INFO - Horizon 01, MAE: 1.43, MAPE: 119922601816.8216, RMSE: 2.01\n",
      "2018-12-10 15:08:54,097 - INFO - Horizon 02, MAE: 1.46, MAPE: 125909808334.2518, RMSE: 2.05\n",
      "2018-12-10 15:08:54,103 - INFO - Horizon 03, MAE: 1.47, MAPE: 129663192058.1517, RMSE: 2.07\n",
      "2018-12-10 15:08:54,108 - INFO - Horizon 04, MAE: 1.48, MAPE: 124139111170.3949, RMSE: 2.09\n",
      "2018-12-10 15:08:54,114 - INFO - Horizon 05, MAE: 1.49, MAPE: 113864128635.3805, RMSE: 2.11\n",
      "2018-12-10 15:08:54,120 - INFO - Horizon 06, MAE: 1.51, MAPE: 109747979595.0303, RMSE: 2.13\n",
      "2018-12-10 15:08:58,373 - INFO - Epoch [80/100] (3402) train_mae: 1.4624, val_mae: 1.5625 lr:0.000002 4.3s\n",
      "2018-12-10 15:09:02,619 - INFO - Epoch [81/100] (3444) train_mae: 1.4627, val_mae: 1.5625 lr:0.000002 4.2s\n",
      "2018-12-10 15:09:06,900 - INFO - Epoch [82/100] (3486) train_mae: 1.4624, val_mae: 1.5625 lr:0.000002 4.3s\n",
      "2018-12-10 15:09:11,187 - INFO - Epoch [83/100] (3528) train_mae: 1.4626, val_mae: 1.5625 lr:0.000002 4.3s\n",
      "2018-12-10 15:09:15,424 - INFO - Epoch [84/100] (3570) train_mae: 1.4625, val_mae: 1.5625 lr:0.000002 4.2s\n",
      "2018-12-10 15:09:19,644 - INFO - Epoch [85/100] (3612) train_mae: 1.4623, val_mae: 1.5625 lr:0.000002 4.2s\n",
      "2018-12-10 15:09:23,863 - INFO - Epoch [86/100] (3654) train_mae: 1.4621, val_mae: 1.5625 lr:0.000002 4.2s\n",
      "2018-12-10 15:09:28,135 - INFO - Epoch [87/100] (3696) train_mae: 1.4621, val_mae: 1.5625 lr:0.000002 4.3s\n",
      "2018-12-10 15:09:32,441 - INFO - Epoch [88/100] (3738) train_mae: 1.4624, val_mae: 1.5625 lr:0.000002 4.3s\n"
     ]
    }
   ],
   "source": [
    "#IF running into ValueError: Variable rnn/basic_rnn_cell/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at\n",
    "#Try restarting kernel\n",
    "os.chdir(os.path.join(base_dir,'..'))\n",
    "#%run run_demo.py --config_filename movia/config.yml --output_filename movia/out/out.npz\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from lib.utils import load_graph_data\n",
    "from model.dcrnn_supervisor import DCRNNSupervisor\n",
    "use_cpu_only = False\n",
    "graph_pkl_filename = 'movia/adj_mx.pkl'\n",
    "tf_config = tf.ConfigProto()\n",
    "\n",
    "if use_cpu_only:\n",
    "    tf_config = tf.ConfigProto(device_count={'GPU': 0})\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "_, _, adj_mx = load_graph_data(graph_pkl_filename)\n",
    "with tf.Session(config=tf_config) as sess:\n",
    "    supervisor = DCRNNSupervisor(adj_mx=adj_mx, **config)\n",
    "    supervisor.train(sess)\n",
    "    #supervisor.load(sess, config['train']['model_filename'])\n",
    "    outputs = supervisor.evaluate(sess)\n",
    "    np.savez_compressed(os.path.join(base_dir,'out.npz'), **outputs)\n",
    "    print('Predictions saved as {}.'.format(os.path.join(base_dir,'out.npz')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIFFUSION = 2\n",
    "2018-12-10 14:40:25,705 - INFO - Horizon 01, MAE: 1.38, MAPE: 111569731185.0971, RMSE: 1.96 \n",
    "2018-12-10 14:40:25,712 - INFO - Horizon 02, MAE: 1.39, MAPE: 115525573123.4882, RMSE: 1.98 \n",
    "2018-12-10 14:40:25,717 - INFO - Horizon 03, MAE: 1.39, MAPE: 118531122300.2530, RMSE: 1.99\n",
    "2018-12-10 14:40:25,723 - INFO - Horizon 04, MAE: 1.39, MAPE: 107190352152.2177, RMSE: 2.00\n",
    "2018-12-10 14:40:25,729 - INFO - Horizon 05, MAE: 1.40, MAPE: 103140687758.3068, RMSE: 2.01\n",
    "2018-12-10 14:40:25,735 - INFO - Horizon 06, MAE: 1.41, MAPE: 102208190672.9279, RMSE: 2.02"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
